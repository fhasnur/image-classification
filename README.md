# Rockpaperscissors Image Classification

This project is an implementation of an image classification model to identify Rock-Paper-Scissors hand gestures using TensorFlow. The model is trained on the Rock-Paper-Scissors hand-drawn dataset, and can accurately classify new images from those drawings.

## Requirements
- TensorFlow 2.x
- NumPy
- Matplotlib
- Keras

## Datasets
The dataset used for training and testing the model consists of images of Rock-Paper-Scissors hand gestures. The images were collected from various sources, including online image search and the open-source RPS-Dataset. The dataset includes images of hands making the Rock, Paper, and Scissors gestures, with a total of 726 images. The dataset can be obtained from https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip
